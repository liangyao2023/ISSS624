[
  {
    "objectID": "Handson_Ex/Handson_Ex03/Handson_Ex03.html",
    "href": "Handson_Ex/Handson_Ex03/Handson_Ex03.html",
    "title": "Hands on Excercise 3",
    "section": "",
    "text": "Spatial interaction represent the flow of people, material, or information between locations in geographical space. It encompasses everything from freight shipments, energy flows, and the global trade in rare antiquities, to flight schedules, rush hour woes, and pedestrian foot traffic.\nEach spatial interaction, as an analogy for a set of movements, is composed of a discrete origin/destination pair. Each pair can be represented as a cell in a matrix where rows are related to the locations (centroids) of origin, while columns are related to locations (centroids) of destination. Such a matrix is commonly known as an origin/destination matrix, or a spatial interaction matrix.\nIn this hands-on exercise, you will learn how to build an OD matrix by using Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall. By the end of this hands-on exercise, you will be able:\n\nto import and extract OD data for a selected time interval,\nto import and save geospatial data (i.e. bus stops and mpsz) into sf tibble data frame objects,\nto populate planning subzone code into bus stops sf tibble data frame,\nto construct desire lines geospatial data from the OD data, and\nto visualise passenger volume by origin and destination bus stops by using the desire lines data."
  },
  {
    "objectID": "Handson_Ex/Handson_Ex03/Handson_Ex03.html#overview",
    "href": "Handson_Ex/Handson_Ex03/Handson_Ex03.html#overview",
    "title": "Hands on Excercise 3",
    "section": "",
    "text": "Spatial interaction represent the flow of people, material, or information between locations in geographical space. It encompasses everything from freight shipments, energy flows, and the global trade in rare antiquities, to flight schedules, rush hour woes, and pedestrian foot traffic.\nEach spatial interaction, as an analogy for a set of movements, is composed of a discrete origin/destination pair. Each pair can be represented as a cell in a matrix where rows are related to the locations (centroids) of origin, while columns are related to locations (centroids) of destination. Such a matrix is commonly known as an origin/destination matrix, or a spatial interaction matrix.\nIn this hands-on exercise, you will learn how to build an OD matrix by using Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall. By the end of this hands-on exercise, you will be able:\n\nto import and extract OD data for a selected time interval,\nto import and save geospatial data (i.e. bus stops and mpsz) into sf tibble data frame objects,\nto populate planning subzone code into bus stops sf tibble data frame,\nto construct desire lines geospatial data from the OD data, and\nto visualise passenger volume by origin and destination bus stops by using the desire lines data."
  },
  {
    "objectID": "Handson_Ex/Handson_Ex03/Handson_Ex03.html#preparing-flow-data",
    "href": "Handson_Ex/Handson_Ex03/Handson_Ex03.html#preparing-flow-data",
    "title": "Hands on Excercise 3",
    "section": "2 Preparing Flow Data",
    "text": "2 Preparing Flow Data\n\n2.1 Get ready\n\n\nCode\npacman::p_load(tmap, sf, DT, stplanr,\n               performance,\n               ggpubr, tidyverse)\n\n\n\n\n2.2 Importing the OD Data\nImport the passenger volume by origin destination bus stops data.\n\n\nCode\nodbus &lt;- read_csv(\"./data/aspatial/origin_destination_bus_202310.csv\") %&gt;%\n  mutate(ORIGIN_PT_CODE = as.factor(ORIGIN_PT_CODE),\n         DESTINATION_PT_CODE = as.factor(DESTINATION_PT_CODE))\n\n\nCheck the data.\n\n\nCode\nglimpse(odbus)\n\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 04168, 04168, 80119, 80119, 44069, 20281, 20281, 1…\n$ DESTINATION_PT_CODE &lt;fct&gt; 10051, 10051, 90079, 90079, 17229, 20141, 20141, 1…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\n\n\n2.3 Extracting Data\nFor the purpose of this exercise, we will extract commuting flows on weekday and between 6 and 9 o’clock.\n\n\nCode\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\nSave the output in rds format\n\n\nCode\nwrite_rds(odbus6_9, \"./data/rds/odbus6_9.rds\")\n\n\nCan extract data from saved file again.\n\n\nCode\n# read from saved file.\n# odbus6_9 &lt;- read_rds(\"chap15/data/rds/odbus6_9.rds\")"
  },
  {
    "objectID": "Handson_Ex/Handson_Ex03/Handson_Ex03.html#working-with-geospatial-data",
    "href": "Handson_Ex/Handson_Ex03/Handson_Ex03.html#working-with-geospatial-data",
    "title": "Hands on Excercise 3",
    "section": "3 Working with GeoSpatial Data",
    "text": "3 Working with GeoSpatial Data\n\n3.1 Importing Data\nUse sf package to read master plan subzone data and bus stop location data.\n\n\nCode\nmpsz &lt;- st_read(dsn = \"./data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;% st_transform(crs = 3414)\n\n\nReading layer `MPSZ-2019' from data source \n  `/Users/SMU/liangyao2023/ISSS624/Handson_Ex/Handson_Ex03/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n\nCode\nbusstop &lt;- st_read(dsn = \"./data/geospatial\",\n                   layer = \"BusStop\")  %&gt;% st_transform(crs = 3414)\n\n\nReading layer `BusStop' from data source \n  `/Users/SMU/liangyao2023/ISSS624/Handson_Ex/Handson_Ex03/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\n\n\n\n\n\nTip\n\n\n\nHere we use “st_transform(crs = 3414)” to change the coordinate from decimal degree to meters.\n\n\n\n\n3.2 Wrangling Data\nCombine the bus stop location with the Singapore subzone map.\n\n\nCode\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\n\n\nst_intersection() is used to perform point and polygon overly and the output will be in point sf object.\nselect() of dplyr package is then use to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame.\nfive bus stops are excluded in the resultant data frame because they are outside of Singapore boundary.\n\n\n\nCode\nglimpse(busstop_mpsz)\n\n\nRows: 5,156\nColumns: 2\n$ BUS_STOP_N &lt;chr&gt; \"13099\", \"13089\", \"06151\", \"13211\", \"13139\", \"13109\", \"1311…\n$ SUBZONE_C  &lt;chr&gt; \"RVSZ05\", \"RVSZ05\", \"SRSZ01\", \"SRSZ01\", \"SRSZ01\", \"SRSZ01\",…\n\n\nNext, we are going to append the planning subzone code from busstop_mpsz data frame onto odbus7_9 data frame.\n\n\nCode\nod_data &lt;- left_join(odbus6_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\n\nBefore continue, it is a good practice for us to check for duplicating records.\n\n\nCode\nod_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\n# A tibble: 1,186 × 4\n   ORIGIN_BS DESTIN_BS TRIPS ORIGIN_SZ\n   &lt;chr&gt;     &lt;fct&gt;     &lt;dbl&gt; &lt;chr&gt;    \n 1 11009     01341         1 QTSZ01   \n 2 11009     01341         1 QTSZ01   \n 3 11009     01411         4 QTSZ01   \n 4 11009     01411         4 QTSZ01   \n 5 11009     01421        17 QTSZ01   \n 6 11009     01421        17 QTSZ01   \n 7 11009     01511        19 QTSZ01   \n 8 11009     01511        19 QTSZ01   \n 9 11009     01521         2 QTSZ01   \n10 11009     01521         2 QTSZ01   \n# ℹ 1,176 more rows\n\n\nIf duplicated records are found, the code chunk below will be used to retain the unique records.\n\n\nCode\nod_data &lt;- unique(od_data)\n\n\nNext, we will update od_data data frame cwith the planning subzone codes.\n\n\nCode\nod_data &lt;- left_join(od_data , busstop_mpsz,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\n\n\n\nCode\nod_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\n# A tibble: 1,350 × 5\n   ORIGIN_BS DESTIN_BS TRIPS ORIGIN_SZ SUBZONE_C\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    \n 1 01013     51071         2 RCSZ10    CCSZ01   \n 2 01013     51071         2 RCSZ10    CCSZ01   \n 3 01112     51071        66 RCSZ10    CCSZ01   \n 4 01112     51071        66 RCSZ10    CCSZ01   \n 5 01112     53041         4 RCSZ10    BSSZ01   \n 6 01112     53041         4 RCSZ10    BSSZ01   \n 7 01121     51071         8 RCSZ04    CCSZ01   \n 8 01121     51071         8 RCSZ04    CCSZ01   \n 9 01121     82221         1 RCSZ04    GLSZ05   \n10 01121     82221         1 RCSZ04    GLSZ05   \n# ℹ 1,340 more rows\n\n\n\n\nCode\nod_data &lt;- unique(od_data)\n\n\n\n\nCode\nod_data &lt;- od_data %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\n\nIt is time to save the output into an rds file format.\n\n\nCode\nwrite_rds(od_data, \"./data/rds/od_data.rds\")\n\n\n\n\nCode\nod_data &lt;- read_rds(\"./data/rds/od_data.rds\")\n\n\n\n\n3.3 Visualising Spatial Interaction\nIn this section, you will learn how to prepare a desire line by using stplanr package.\n\n3.3.1 Removing intra-zonal flows\nWe will not plot the intra-zonal flows. The code chunk below will be used to remove intra-zonal flows.\n\n\nCode\nod_data1 &lt;- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]\n\n\n\n\n3.3.2 Creating desire lines\nIn this code chunk below, od2line() of stplanr package is used to create the desire lines.\n\n\nCode\nflowLine &lt;- od2line(flow = od_data1, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\n\n\n\n3.3.3 Visualising the desire lines\nTo visualise the resulting desire lines, the code chunk below is used.\n\n\nCode\ntm_shape(mpsz) +\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons() +\nflowLine %&gt;%  \ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.5)\n\n\n\n\n\nWhen the flow data are very messy and highly skewed like the one shown above, it is wiser to focus on selected flows, for example flow greater than or equal to 5000 as shown below.\n\n\nCode\ntm_shape(mpsz) +\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons() +\nflowLine %&gt;%  \n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.5)"
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "As city-wide urban infrastructures such as buses, taxis, mass rapid transit, public utilities and roads become digital, the datasets obtained can be used as a framework for tracking movement patterns through space and time. This is particularly true with the recent trend of massive deployment of pervasive computing technologies such as GPS and RFID on the vehicles. For example, routes and ridership data were collected with the use of smart cards and Global Positioning System (GPS) devices available on the public buses. These massive movement data collected are likely to contain structure and patterns that provide useful information about characteristics of the measured phenomena. The identification, analysis and comparison of such patterns will provide greater insights on human movement and behaviours within a city. These understandings will potentially contribute to a better urban management and useful information for urban transport services providers both from the private and public sector to formulate informed decision to gain competitive advantage.\nIn real-world practices, the use of these massive locational aware data, however, tend to be confined to simple tracking and mapping with GIS applications. This is mainly due to a general lack of functions in conventional GIS which is capable of analysing and model spatial and spatio-temporal data effectively.\n\n\n\nExploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate Local Indicators of Spatial Association (GLISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.\n\n\n\nFirst of all, load needing packages.\n\n\nCode\npacman::p_load(sf, tmap, tidyverse, sfdep, Kendall)\n\n\n\n\nFor the purpose of this take-home exercise, Passenger Volume by Origin Destination Bus Stops downloaded from LTA DataMall will be used.\nImport the passenger volume by origin destination bus stops data.\n\n\nCode\nodbus = read_csv(\"./data/aspatial/origin_destination_bus_202308.csv\")  %&gt;%\n  mutate(ORIGIN_PT_CODE = as.factor(ORIGIN_PT_CODE),\n         DESTINATION_PT_CODE = as.factor(DESTINATION_PT_CODE))\n\n\n\n\n\nTwo geospatial data will be used in this study, they are:\n\nBus Stop Location from LTA DataMall. It provides information about all the bus stops currently being serviced by buses, including the bus stop code (identifier) and location coordinates.\n\n\n\nCode\nbusstop = st_read(dsn = \"./data/geospatial/BusStopLocation_Jul2023\",\n                   layer = \"BusStop\")  %&gt;% st_transform(crs = 3414)\n\n\nReading layer `BusStop' from data source \n  `/Users/SMU/liangyao2023/ISSS624/Takehome_Ex/Takehome_Ex01/data/geospatial/BusStopLocation_Jul2023' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nhexagon, a hexagon layer of 250m is provided to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA.\n\n\n\nCode\nhexagon = st_read(dsn = \"./data/geospatial/hexagon\",\n                   layer = \"hexagon\")  %&gt;% st_transform(crs = 3414)\n\n\nReading layer `hexagon' from data source \n  `/Users/SMU/liangyao2023/ISSS624/Takehome_Ex/Takehome_Ex01/data/geospatial/hexagon' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3125 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21506.33 xmax: 50010.26 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\n\n\n\n\n\n\nThe specific tasks of this take-home exercise are as follows:\n\n\n\nWith reference to the time intervals provided in the table below, compute the passenger trips generated by origin at the hexagon level,\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nDisplay the geographical distribution of the passenger trips by using appropriate geovisualisation methods,\nDescribe the spatial patterns revealed by the geovisualisation (not more than 200 words per visual).\n\n\n\nExtract peak data, and combine 4 time intervals data for further use.\n\n\nCode\npeak_trips &lt;- bind_rows(\n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  mutate(interval = \"weekday_6_9\"),\n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 17 &\n           TIME_PER_HOUR &lt;= 20) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  mutate(interval = \"weekday_17_20\"),\n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 11 &\n           TIME_PER_HOUR &lt;= 14) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  mutate(interval = \"weekend_11_14\"),\n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 16 &\n           TIME_PER_HOUR &lt;= 19) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  mutate(interval = \"weekend_16_19\"))\n\nglimpse(peak_trips)\n\n\nRows: 20,044\nColumns: 3\n$ ORIGIN_PT_CODE &lt;fct&gt; 01012, 01013, 01019, 01029, 01039, 01059, 01109, 01112,…\n$ TRIPS          &lt;dbl&gt; 1973, 952, 1789, 2561, 2938, 1651, 161, 8492, 9015, 424…\n$ interval       &lt;chr&gt; \"weekday_6_9\", \"weekday_6_9\", \"weekday_6_9\", \"weekday_6…\n\n\n\n\n\nFirst we need to combine bus stops and hexagon data.\n\n\nCode\nbusstop_hexagon &lt;- st_intersection(hexagon, busstop) %&gt;%\n  select(BUS_STOP_N,id) %&gt;%\n  st_drop_geometry()\n\n\nThen combine passenger trip data with geospatial data.\n\n\nCode\norigin_trips &lt;- left_join(peak_trips, busstop_hexagon,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = id) %&gt;%\n  group_by(ORIGIN_SZ) %&gt;%\n  summarise(TRIPS = sum(TRIPS))\n\n\nDuplication check before continue:\n\n\nCode\norigin_trips %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\n# A tibble: 0 × 2\n# ℹ 2 variables: ORIGIN_SZ &lt;dbl&gt;, TRIPS &lt;dbl&gt;\n\n\nRe-join with hexagon data and check for duplication.\n\n\nCode\npeaktrip_hex &lt;- left_join(hexagon, origin_trips, by = c(\"id\" = \"ORIGIN_SZ\")) \n\n\n\n\nCode\npeaktrip_hex %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\nSimple feature collection with 0 features and 7 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 0 × 8\n# ℹ 8 variables: fid &lt;dbl&gt;, id &lt;dbl&gt;, left &lt;dbl&gt;, top &lt;dbl&gt;, right &lt;dbl&gt;,\n#   bottom &lt;dbl&gt;, TRIPS &lt;dbl&gt;, geometry &lt;GEOMETRY [m]&gt;\n\n\n\n\n\n4.1.3.1 Firstly, we may want check the geographical distribution of all bus trips to gather a full glimpse.\nBelow code chunk aims at wrangling the odbus data for visualization.\n\n\nCode\nodbus_by_ptcode &lt;- odbus %&gt;%\n  select(ORIGIN_PT_CODE,TOTAL_TRIPS,DAY_TYPE) %&gt;%\n  group_by(ORIGIN_PT_CODE, DAY_TYPE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) \n\nbus_trips &lt;- left_join(odbus_by_ptcode, busstop_hexagon,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = id) %&gt;%\n  group_by(ORIGIN_SZ) %&gt;%\n  summarise(TRIPS = sum(TRIPS))\n\nbustrip_hex &lt;- left_join(hexagon, bus_trips, by = c(\"id\" = \"ORIGIN_SZ\")) \n\n\nNow we can visualize the distribution of total bus trips.\n\n\nCode\ntmap_mode(\"plot\")\ntm_shape(bustrip_hex) +\n  tm_fill(\"TRIPS\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Passenger trips\",\n          colorNA = NULL,\n          showNA = FALSE) +\n  tm_layout(main.title = \"Singapore Passenger Trips during Aug 2023\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\n4.1.3.2 Then, let’s check out the distribution of peak time trips of 4 time intervals in total.\n\n\nCode\ntmap_mode(\"plot\")\ntm_shape(peaktrip_hex) +\n  tm_fill(\"TRIPS\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Passenger trips\",\n          colorNA = NULL,\n          showNA = FALSE) +\n  tm_layout(main.title = \"Peak Time Passenger Trips\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservation:\nThere’s no obvious difference between the distribution of total bus trips and peak time bus trips, so the peak time data we chose could be a meaningful representation of total trips.\n\n\n4.1.3.3 Then, to display the geographical distribution of 4 time intervals seperately for comparison:\n\nRegenerate trip data with the “interval” column to indicate different time intervals.\n\n\nCode\npeak_trips_interval &lt;- left_join(peak_trips, busstop_hexagon,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = id) %&gt;%\n  group_by(ORIGIN_SZ, interval) %&gt;%\n  summarise(TRIPS = sum(TRIPS)) %&gt;% \n  mutate(daily_trips = \n           ifelse(grepl(\"weekday\",interval), ceiling(TRIPS/22), ceiling(TRIPS/9)))\n\nglimpse(peak_trips_interval)\n\n\nRows: 5,835\nColumns: 4\nGroups: ORIGIN_SZ [1,469]\n$ ORIGIN_SZ   &lt;dbl&gt; 185, 185, 185, 185, 249, 249, 249, 249, 253, 253, 253, 253…\n$ interval    &lt;chr&gt; \"weekday_17_20\", \"weekday_6_9\", \"weekend_11_14\", \"weekend_…\n$ TRIPS       &lt;dbl&gt; 417, 62, 5, 65, 249, 44, 27, 54, 110, 50, 24, 26, 325, 82,…\n$ daily_trips &lt;dbl&gt; 19, 3, 1, 8, 12, 2, 3, 6, 5, 3, 3, 3, 15, 4, 5, 6, 10, 4, …\n\n\n\n\n\n\n\n\nImportant\n\n\n\nHere I create a column “daily_trips” to find number of trips per day, since it’s hard to compare the absolute number when we are differentiating weekday and weekend peak times intervals. For Aug 2023, there are 31 days in which 8 days are weekends and 1 day is National holiday.\n\n\n\n\nCode\npeak_totaltrips_interval &lt;- peak_trips_interval %&gt;%\n  select(ORIGIN_SZ,interval,TRIPS) %&gt;%\n  pivot_wider(names_from = interval, \n              values_from = TRIPS, \n              values_fill = NA)\n\npeak_dailytrips_interval &lt;- peak_trips_interval %&gt;%\n  select(ORIGIN_SZ,interval,daily_trips) %&gt;%\n  pivot_wider(names_from = interval, \n              values_from = daily_trips, \n              values_fill = NA)\n\n\nJoin back with hexagon.\n\n\nCode\ninterval_totaltrip_hex &lt;- left_join(hexagon, peak_totaltrips_interval,\n                           by = c(\"id\" = \"ORIGIN_SZ\")) \n\ninterval_dailytrip_hex &lt;- left_join(hexagon, peak_dailytrips_interval,\n                           by = c(\"id\" = \"ORIGIN_SZ\")) \n\n\nThen we can draw graph for each time intervals.\n1) Visualize total trip distribution for each time intervals.\n\n\nCode\ntmap_mode(\"plot\")\ntm_shape(interval_totaltrip_hex)+ \n  tm_polygons(c(\"weekday_6_9\",\"weekday_17_20\",\"weekend_11_14\",\"weekend_16_19\"),\n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"\",\n          colorNA = NULL,\n          showNA = FALSE) + \n  tm_layout(panel.show = TRUE,\n            panel.labels = c(\"Weekday 6-9am\", \"Weekday 5-8pm\", \"Weekend 11am-2pm\", \"Weekend 4-7pm\")) \n\n\n\n\n\n2) Visualize daily trip distribution for each time intervals.\n\n\nCode\n#tmap_mode(\"view\")\ntm_shape(interval_dailytrip_hex)+ \n  tm_polygons(c(\"weekday_6_9\",\"weekday_17_20\",\"weekend_11_14\",\"weekend_16_19\"),\n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"\",\n          colorNA = NULL,\n          showNA = FALSE) + \n  tm_layout(panel.show = TRUE,\n            panel.labels = c(\"Weekday 6-9am\", \"Weekday 5-8pm\", \"Weekend 11am-2pm\", \"Weekend 4-7pm\"))\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservation:\n\nFrom the color scale we can find that the number of bus trips at night peak time intervals is larger than morning peak time intervals.\nHeavy trip hexagons are more disperse throughout the island during morning peak time intervals, and more concentrate in similar locations during night peak time intervals.\n\n\n\n\n\n\n\nWith reference to the passenger trips by origin at the hexagon level for the four time intervals given above:\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values,\nPrepared EHSA maps of the Gi* values of the passenger trips by origin at the hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05).\nWith reference to the EHSA maps and data visualisation prepared, describe the spatial patterns reveled. (not more than 250 words per cluster).\n\n\n\nFirst we need to extract the passenger trips data during 4 peak time intervals from odbus.\n\n\nCode\npeak_trips_hour &lt;- bind_rows(\n  left_join(busstop_hexagon, \n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;% \n  group_by(ORIGIN_PT_CODE,TIME_PER_HOUR) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  rename('BUS_STOP_N'='ORIGIN_PT_CODE'), by = 'BUS_STOP_N'),\n  left_join(busstop_hexagon, \n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 17 &\n           TIME_PER_HOUR &lt;= 20) %&gt;% \n  group_by(ORIGIN_PT_CODE,TIME_PER_HOUR) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  rename('BUS_STOP_N'='ORIGIN_PT_CODE'), by = 'BUS_STOP_N'),\n  left_join(busstop_hexagon, \n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 11 &\n           TIME_PER_HOUR &lt;= 14) %&gt;% \n  group_by(ORIGIN_PT_CODE,TIME_PER_HOUR) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  rename('BUS_STOP_N'='ORIGIN_PT_CODE'), by = 'BUS_STOP_N'),\n  left_join(busstop_hexagon, \n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 16 &\n           TIME_PER_HOUR &lt;= 19) %&gt;%\n  group_by(ORIGIN_PT_CODE,TIME_PER_HOUR) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  rename('BUS_STOP_N'='ORIGIN_PT_CODE'), by = 'BUS_STOP_N'))%&gt;% \n  group_by(id,TIME_PER_HOUR) %&gt;%\n  summarise(TRIPS = sum(TRIPS)) %&gt;%\n  right_join(hexagon %&gt;% select(id, geometry), by = \"id\")\n\n\nAnd then create an space-time cube for the per hour trip data.\n\n\nCode\npeak_trips_h_st &lt;- spacetime(peak_trips_hour %&gt;% ungroup(), \n                     hexagon,\n                      .loc_col = \"id\",\n                      .time_col = \"TIME_PER_HOUR\") %&gt;%\n  complete_spacetime_cube() %&gt;%\n  mutate(TRIPS = replace_na(TRIPS,0))\n\n\n\nHere since the Number of rows does not equal `n time-periods x n locations, I used complete_spacetime_cube() to fill up the cube, rows with no trips would be NA.\n\nBefore continue, we better make sure the peak_st is indeed an space-time cube object.\n\nis_spacetime_cube(peak_trips_h_st)\n\n[1] TRUE\n\n\nThen we need to identify neighbors and to derive an inverse distance weights.\n\n\nCode\npeak_trips_h_nb &lt;- peak_trips_h_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\nprint(head(peak_trips_h_nb, 5))\n\n\n# A tibble: 5 × 6\n     id TIME_PER_HOUR TRIPS      geometry nb        wt       \n  &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;POLYGON [m]&gt; &lt;list&gt;    &lt;list&gt;   \n1    46             6     0         EMPTY &lt;int [3]&gt; &lt;dbl [3]&gt;\n2    51             6     0         EMPTY &lt;int [3]&gt; &lt;dbl [3]&gt;\n3    52             6     0         EMPTY &lt;int [5]&gt; &lt;dbl [5]&gt;\n4    53             6     0         EMPTY &lt;int [5]&gt; &lt;dbl [5]&gt;\n5    54             6     0         EMPTY &lt;int [5]&gt; &lt;dbl [5]&gt;\n\n\nNext we can compute Gi* values for each location base on the space-time cube.\n\n\nCode\npeak_trips_h_gi &lt;- peak_trips_h_nb %&gt;%\n  mutate(TRIPS = replace_na(TRIPS,0)) %&gt;%\n  mutate(gi_star = local_gstar_perm(TRIPS, nb, wt)) %&gt;% \n  tidyr::unnest(gi_star)\n\n\n\n\n\n\nFrom the Mann-Kendall test output, sl = 0 suggests there is a statistically significant trend, and tau all positive indicate increasing trends.\n\n\n\nCode\npeak_trips_h_gi %&gt;%\n  group_by(TIME_PER_HOUR) %&gt;%\n  summarise(mk = list(\n    unclass(\n      MannKendall(gi_star)))) %&gt;%\n unnest_wider(mk)\n\n\n# A tibble: 13 × 6\n   TIME_PER_HOUR   tau    sl      S        D       varS\n           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1             6 0.174     0 827234 4759816  3357820416\n 2             7 0.175     0 834829 4760180. 3357972992\n 3             8 0.177     0 843955 4760172. 3357972992\n 4             9 0.176     0 839093 4760174  3357972992\n 5            11 0.174     0 828071 4760888. 3358277376\n 6            12 0.174     0 829647 4760544. 3358125824\n 7            13 0.174     0 830538 4760536. 3358125824\n 8            14 0.174     0 830136 4760538. 3358125824\n 9            16 0.174     0 830082 4760886. 3358277376\n10            17 0.177     0 842769 4761257  3358428416\n11            18 0.179     0 850284 4760910. 3358277376\n12            19 0.177     0 843922 4760902. 3358277376\n13            20 0.176     0 837154 4760174. 3357972992\n\n\n\n\n\n\n\n\n\nCode\nehsa &lt;- emerging_hotspot_analysis(\n  x = peak_trips_h_st, \n  .var = \"TRIPS\",\n  nsim = 20)\n\n\n\n\n\n\n\nCode\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nBefore plot, join ehsa data back with hexagon.\n\n\nCode\nhex_ehsa &lt;- hexagon %&gt;%\n  left_join(ehsa,\n            by = join_by(id == location))\n\n\nThen we can plot a categorical choropleth map.\n\n\nCode\nehsa_sig &lt;- hex_ehsa  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(hex_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#setting-the-scene",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#setting-the-scene",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "As city-wide urban infrastructures such as buses, taxis, mass rapid transit, public utilities and roads become digital, the datasets obtained can be used as a framework for tracking movement patterns through space and time. This is particularly true with the recent trend of massive deployment of pervasive computing technologies such as GPS and RFID on the vehicles. For example, routes and ridership data were collected with the use of smart cards and Global Positioning System (GPS) devices available on the public buses. These massive movement data collected are likely to contain structure and patterns that provide useful information about characteristics of the measured phenomena. The identification, analysis and comparison of such patterns will provide greater insights on human movement and behaviours within a city. These understandings will potentially contribute to a better urban management and useful information for urban transport services providers both from the private and public sector to formulate informed decision to gain competitive advantage.\nIn real-world practices, the use of these massive locational aware data, however, tend to be confined to simple tracking and mapping with GIS applications. This is mainly due to a general lack of functions in conventional GIS which is capable of analysing and model spatial and spatio-temporal data effectively."
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#objectives",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#objectives",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "Exploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate Local Indicators of Spatial Association (GLISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore."
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#the-data",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#the-data",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "First of all, load needing packages.\n\n\nCode\npacman::p_load(sf, tmap, tidyverse, sfdep, Kendall)\n\n\n\n\nFor the purpose of this take-home exercise, Passenger Volume by Origin Destination Bus Stops downloaded from LTA DataMall will be used.\nImport the passenger volume by origin destination bus stops data.\n\n\nCode\nodbus = read_csv(\"./data/aspatial/origin_destination_bus_202308.csv\")  %&gt;%\n  mutate(ORIGIN_PT_CODE = as.factor(ORIGIN_PT_CODE),\n         DESTINATION_PT_CODE = as.factor(DESTINATION_PT_CODE))\n\n\n\n\n\nTwo geospatial data will be used in this study, they are:\n\nBus Stop Location from LTA DataMall. It provides information about all the bus stops currently being serviced by buses, including the bus stop code (identifier) and location coordinates.\n\n\n\nCode\nbusstop = st_read(dsn = \"./data/geospatial/BusStopLocation_Jul2023\",\n                   layer = \"BusStop\")  %&gt;% st_transform(crs = 3414)\n\n\nReading layer `BusStop' from data source \n  `/Users/SMU/liangyao2023/ISSS624/Takehome_Ex/Takehome_Ex01/data/geospatial/BusStopLocation_Jul2023' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nhexagon, a hexagon layer of 250m is provided to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA.\n\n\n\nCode\nhexagon = st_read(dsn = \"./data/geospatial/hexagon\",\n                   layer = \"hexagon\")  %&gt;% st_transform(crs = 3414)\n\n\nReading layer `hexagon' from data source \n  `/Users/SMU/liangyao2023/ISSS624/Takehome_Ex/Takehome_Ex01/data/geospatial/hexagon' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3125 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21506.33 xmax: 50010.26 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM"
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#the-task",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#the-task",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "The specific tasks of this take-home exercise are as follows:\n\n\n\nWith reference to the time intervals provided in the table below, compute the passenger trips generated by origin at the hexagon level,\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nDisplay the geographical distribution of the passenger trips by using appropriate geovisualisation methods,\nDescribe the spatial patterns revealed by the geovisualisation (not more than 200 words per visual).\n\n\n\nExtract peak data, and combine 4 time intervals data for further use.\n\n\nCode\npeak_trips &lt;- bind_rows(\n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  mutate(interval = \"weekday_6_9\"),\n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 17 &\n           TIME_PER_HOUR &lt;= 20) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  mutate(interval = \"weekday_17_20\"),\n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 11 &\n           TIME_PER_HOUR &lt;= 14) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  mutate(interval = \"weekend_11_14\"),\n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 16 &\n           TIME_PER_HOUR &lt;= 19) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  mutate(interval = \"weekend_16_19\"))\n\nglimpse(peak_trips)\n\n\nRows: 20,044\nColumns: 3\n$ ORIGIN_PT_CODE &lt;fct&gt; 01012, 01013, 01019, 01029, 01039, 01059, 01109, 01112,…\n$ TRIPS          &lt;dbl&gt; 1973, 952, 1789, 2561, 2938, 1651, 161, 8492, 9015, 424…\n$ interval       &lt;chr&gt; \"weekday_6_9\", \"weekday_6_9\", \"weekday_6_9\", \"weekday_6…\n\n\n\n\n\nFirst we need to combine bus stops and hexagon data.\n\n\nCode\nbusstop_hexagon &lt;- st_intersection(hexagon, busstop) %&gt;%\n  select(BUS_STOP_N,id) %&gt;%\n  st_drop_geometry()\n\n\nThen combine passenger trip data with geospatial data.\n\n\nCode\norigin_trips &lt;- left_join(peak_trips, busstop_hexagon,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = id) %&gt;%\n  group_by(ORIGIN_SZ) %&gt;%\n  summarise(TRIPS = sum(TRIPS))\n\n\nDuplication check before continue:\n\n\nCode\norigin_trips %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\n# A tibble: 0 × 2\n# ℹ 2 variables: ORIGIN_SZ &lt;dbl&gt;, TRIPS &lt;dbl&gt;\n\n\nRe-join with hexagon data and check for duplication.\n\n\nCode\npeaktrip_hex &lt;- left_join(hexagon, origin_trips, by = c(\"id\" = \"ORIGIN_SZ\")) \n\n\n\n\nCode\npeaktrip_hex %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\nSimple feature collection with 0 features and 7 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 0 × 8\n# ℹ 8 variables: fid &lt;dbl&gt;, id &lt;dbl&gt;, left &lt;dbl&gt;, top &lt;dbl&gt;, right &lt;dbl&gt;,\n#   bottom &lt;dbl&gt;, TRIPS &lt;dbl&gt;, geometry &lt;GEOMETRY [m]&gt;\n\n\n\n\n\n4.1.3.1 Firstly, we may want check the geographical distribution of all bus trips to gather a full glimpse.\nBelow code chunk aims at wrangling the odbus data for visualization.\n\n\nCode\nodbus_by_ptcode &lt;- odbus %&gt;%\n  select(ORIGIN_PT_CODE,TOTAL_TRIPS,DAY_TYPE) %&gt;%\n  group_by(ORIGIN_PT_CODE, DAY_TYPE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) \n\nbus_trips &lt;- left_join(odbus_by_ptcode, busstop_hexagon,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = id) %&gt;%\n  group_by(ORIGIN_SZ) %&gt;%\n  summarise(TRIPS = sum(TRIPS))\n\nbustrip_hex &lt;- left_join(hexagon, bus_trips, by = c(\"id\" = \"ORIGIN_SZ\")) \n\n\nNow we can visualize the distribution of total bus trips.\n\n\nCode\ntmap_mode(\"plot\")\ntm_shape(bustrip_hex) +\n  tm_fill(\"TRIPS\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Passenger trips\",\n          colorNA = NULL,\n          showNA = FALSE) +\n  tm_layout(main.title = \"Singapore Passenger Trips during Aug 2023\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\n4.1.3.2 Then, let’s check out the distribution of peak time trips of 4 time intervals in total.\n\n\nCode\ntmap_mode(\"plot\")\ntm_shape(peaktrip_hex) +\n  tm_fill(\"TRIPS\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Passenger trips\",\n          colorNA = NULL,\n          showNA = FALSE) +\n  tm_layout(main.title = \"Peak Time Passenger Trips\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservation:\nThere’s no obvious difference between the distribution of total bus trips and peak time bus trips, so the peak time data we chose could be a meaningful representation of total trips.\n\n\n4.1.3.3 Then, to display the geographical distribution of 4 time intervals seperately for comparison:\n\nRegenerate trip data with the “interval” column to indicate different time intervals.\n\n\nCode\npeak_trips_interval &lt;- left_join(peak_trips, busstop_hexagon,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = id) %&gt;%\n  group_by(ORIGIN_SZ, interval) %&gt;%\n  summarise(TRIPS = sum(TRIPS)) %&gt;% \n  mutate(daily_trips = \n           ifelse(grepl(\"weekday\",interval), ceiling(TRIPS/22), ceiling(TRIPS/9)))\n\nglimpse(peak_trips_interval)\n\n\nRows: 5,835\nColumns: 4\nGroups: ORIGIN_SZ [1,469]\n$ ORIGIN_SZ   &lt;dbl&gt; 185, 185, 185, 185, 249, 249, 249, 249, 253, 253, 253, 253…\n$ interval    &lt;chr&gt; \"weekday_17_20\", \"weekday_6_9\", \"weekend_11_14\", \"weekend_…\n$ TRIPS       &lt;dbl&gt; 417, 62, 5, 65, 249, 44, 27, 54, 110, 50, 24, 26, 325, 82,…\n$ daily_trips &lt;dbl&gt; 19, 3, 1, 8, 12, 2, 3, 6, 5, 3, 3, 3, 15, 4, 5, 6, 10, 4, …\n\n\n\n\n\n\n\n\nImportant\n\n\n\nHere I create a column “daily_trips” to find number of trips per day, since it’s hard to compare the absolute number when we are differentiating weekday and weekend peak times intervals. For Aug 2023, there are 31 days in which 8 days are weekends and 1 day is National holiday.\n\n\n\n\nCode\npeak_totaltrips_interval &lt;- peak_trips_interval %&gt;%\n  select(ORIGIN_SZ,interval,TRIPS) %&gt;%\n  pivot_wider(names_from = interval, \n              values_from = TRIPS, \n              values_fill = NA)\n\npeak_dailytrips_interval &lt;- peak_trips_interval %&gt;%\n  select(ORIGIN_SZ,interval,daily_trips) %&gt;%\n  pivot_wider(names_from = interval, \n              values_from = daily_trips, \n              values_fill = NA)\n\n\nJoin back with hexagon.\n\n\nCode\ninterval_totaltrip_hex &lt;- left_join(hexagon, peak_totaltrips_interval,\n                           by = c(\"id\" = \"ORIGIN_SZ\")) \n\ninterval_dailytrip_hex &lt;- left_join(hexagon, peak_dailytrips_interval,\n                           by = c(\"id\" = \"ORIGIN_SZ\")) \n\n\nThen we can draw graph for each time intervals.\n1) Visualize total trip distribution for each time intervals.\n\n\nCode\ntmap_mode(\"plot\")\ntm_shape(interval_totaltrip_hex)+ \n  tm_polygons(c(\"weekday_6_9\",\"weekday_17_20\",\"weekend_11_14\",\"weekend_16_19\"),\n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"\",\n          colorNA = NULL,\n          showNA = FALSE) + \n  tm_layout(panel.show = TRUE,\n            panel.labels = c(\"Weekday 6-9am\", \"Weekday 5-8pm\", \"Weekend 11am-2pm\", \"Weekend 4-7pm\")) \n\n\n\n\n\n2) Visualize daily trip distribution for each time intervals.\n\n\nCode\n#tmap_mode(\"view\")\ntm_shape(interval_dailytrip_hex)+ \n  tm_polygons(c(\"weekday_6_9\",\"weekday_17_20\",\"weekend_11_14\",\"weekend_16_19\"),\n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"\",\n          colorNA = NULL,\n          showNA = FALSE) + \n  tm_layout(panel.show = TRUE,\n            panel.labels = c(\"Weekday 6-9am\", \"Weekday 5-8pm\", \"Weekend 11am-2pm\", \"Weekend 4-7pm\"))\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservation:\n\nFrom the color scale we can find that the number of bus trips at night peak time intervals is larger than morning peak time intervals.\nHeavy trip hexagons are more disperse throughout the island during morning peak time intervals, and more concentrate in similar locations during night peak time intervals.\n\n\n\n\n\n\n\nWith reference to the passenger trips by origin at the hexagon level for the four time intervals given above:\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values,\nPrepared EHSA maps of the Gi* values of the passenger trips by origin at the hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05).\nWith reference to the EHSA maps and data visualisation prepared, describe the spatial patterns reveled. (not more than 250 words per cluster).\n\n\n\nFirst we need to extract the passenger trips data during 4 peak time intervals from odbus.\n\n\nCode\npeak_trips_hour &lt;- bind_rows(\n  left_join(busstop_hexagon, \n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;% \n  group_by(ORIGIN_PT_CODE,TIME_PER_HOUR) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  rename('BUS_STOP_N'='ORIGIN_PT_CODE'), by = 'BUS_STOP_N'),\n  left_join(busstop_hexagon, \n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 17 &\n           TIME_PER_HOUR &lt;= 20) %&gt;% \n  group_by(ORIGIN_PT_CODE,TIME_PER_HOUR) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  rename('BUS_STOP_N'='ORIGIN_PT_CODE'), by = 'BUS_STOP_N'),\n  left_join(busstop_hexagon, \n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 11 &\n           TIME_PER_HOUR &lt;= 14) %&gt;% \n  group_by(ORIGIN_PT_CODE,TIME_PER_HOUR) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  rename('BUS_STOP_N'='ORIGIN_PT_CODE'), by = 'BUS_STOP_N'),\n  left_join(busstop_hexagon, \n  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 16 &\n           TIME_PER_HOUR &lt;= 19) %&gt;%\n  group_by(ORIGIN_PT_CODE,TIME_PER_HOUR) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  rename('BUS_STOP_N'='ORIGIN_PT_CODE'), by = 'BUS_STOP_N'))%&gt;% \n  group_by(id,TIME_PER_HOUR) %&gt;%\n  summarise(TRIPS = sum(TRIPS)) %&gt;%\n  right_join(hexagon %&gt;% select(id, geometry), by = \"id\")\n\n\nAnd then create an space-time cube for the per hour trip data.\n\n\nCode\npeak_trips_h_st &lt;- spacetime(peak_trips_hour %&gt;% ungroup(), \n                     hexagon,\n                      .loc_col = \"id\",\n                      .time_col = \"TIME_PER_HOUR\") %&gt;%\n  complete_spacetime_cube() %&gt;%\n  mutate(TRIPS = replace_na(TRIPS,0))\n\n\n\nHere since the Number of rows does not equal `n time-periods x n locations, I used complete_spacetime_cube() to fill up the cube, rows with no trips would be NA.\n\nBefore continue, we better make sure the peak_st is indeed an space-time cube object.\n\nis_spacetime_cube(peak_trips_h_st)\n\n[1] TRUE\n\n\nThen we need to identify neighbors and to derive an inverse distance weights.\n\n\nCode\npeak_trips_h_nb &lt;- peak_trips_h_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\nprint(head(peak_trips_h_nb, 5))\n\n\n# A tibble: 5 × 6\n     id TIME_PER_HOUR TRIPS      geometry nb        wt       \n  &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;POLYGON [m]&gt; &lt;list&gt;    &lt;list&gt;   \n1    46             6     0         EMPTY &lt;int [3]&gt; &lt;dbl [3]&gt;\n2    51             6     0         EMPTY &lt;int [3]&gt; &lt;dbl [3]&gt;\n3    52             6     0         EMPTY &lt;int [5]&gt; &lt;dbl [5]&gt;\n4    53             6     0         EMPTY &lt;int [5]&gt; &lt;dbl [5]&gt;\n5    54             6     0         EMPTY &lt;int [5]&gt; &lt;dbl [5]&gt;\n\n\nNext we can compute Gi* values for each location base on the space-time cube.\n\n\nCode\npeak_trips_h_gi &lt;- peak_trips_h_nb %&gt;%\n  mutate(TRIPS = replace_na(TRIPS,0)) %&gt;%\n  mutate(gi_star = local_gstar_perm(TRIPS, nb, wt)) %&gt;% \n  tidyr::unnest(gi_star)\n\n\n\n\n\n\nFrom the Mann-Kendall test output, sl = 0 suggests there is a statistically significant trend, and tau all positive indicate increasing trends.\n\n\n\nCode\npeak_trips_h_gi %&gt;%\n  group_by(TIME_PER_HOUR) %&gt;%\n  summarise(mk = list(\n    unclass(\n      MannKendall(gi_star)))) %&gt;%\n unnest_wider(mk)\n\n\n# A tibble: 13 × 6\n   TIME_PER_HOUR   tau    sl      S        D       varS\n           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1             6 0.174     0 827234 4759816  3357820416\n 2             7 0.175     0 834829 4760180. 3357972992\n 3             8 0.177     0 843955 4760172. 3357972992\n 4             9 0.176     0 839093 4760174  3357972992\n 5            11 0.174     0 828071 4760888. 3358277376\n 6            12 0.174     0 829647 4760544. 3358125824\n 7            13 0.174     0 830538 4760536. 3358125824\n 8            14 0.174     0 830136 4760538. 3358125824\n 9            16 0.174     0 830082 4760886. 3358277376\n10            17 0.177     0 842769 4761257  3358428416\n11            18 0.179     0 850284 4760910. 3358277376\n12            19 0.177     0 843922 4760902. 3358277376\n13            20 0.176     0 837154 4760174. 3357972992\n\n\n\n\n\n\n\n\n\nCode\nehsa &lt;- emerging_hotspot_analysis(\n  x = peak_trips_h_st, \n  .var = \"TRIPS\",\n  nsim = 20)\n\n\n\n\n\n\n\nCode\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nBefore plot, join ehsa data back with hexagon.\n\n\nCode\nhex_ehsa &lt;- hexagon %&gt;%\n  left_join(ehsa,\n            by = join_by(id == location))\n\n\nThen we can plot a categorical choropleth map.\n\n\nCode\nehsa_sig &lt;- hex_ehsa  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(hex_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/data/geospatial/MPSZ-2019.html",
    "href": "Takehome_Ex/Takehome_Ex01/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624 Geospatial Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Inclass_Ex/Inclass_Ex03/data/geospatial/MPSZ-2019.html",
    "href": "Inclass_Ex/Inclass_Ex03/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624 Geospatial Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Inclass_Ex/Inclass_Ex01/data/geospatial/MPSZ-2019.html",
    "href": "Inclass_Ex/Inclass_Ex01/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624 Geospatial Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Handson_Ex/Handson_Ex03/data/geospatial/MPSZ-2019.html",
    "href": "Handson_Ex/Handson_Ex03/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624 Geospatial Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/data/geospatial/hexagon/hexagon.html",
    "href": "Takehome_Ex/Takehome_Ex01/data/geospatial/hexagon/hexagon.html",
    "title": "ISSS624 Geospatial Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n                 +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs 0 0     false"
  }
]