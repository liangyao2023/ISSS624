---
title: "In Class Exercise 3"
author: "LIANG YAO"
date: '2 Dec 2023'
date-modified: "`r Sys.Date()`"
execute: 
  warning: false
  echo: true
  eval: true
format: 
  html: 
    code-fold: true
    code-summary: "Show the code"
---

## **1 Preparing Flow Data**

### **1.1 Get ready**

```{r}
pacman::p_load(tmap, sf, DT, sp, reshape2,
               ggpubr, units, tidyverse)
```

### **1.2 The Data**

This exercise is a continuation of **Chapter 15: Processing and Visualising Flow Data** and the following data will be used:

-   *od_data.rds*, weekday morning peak passenger flows at planning subzone level.

-   *mpsz.rds*, URA Master Plan 2019 Planning Subzone boundary in simple feature tibble data frame format.

Beside these two data sets, an additional attribute data file called pop.csv will be provided.

Import the population data.

```{r}
pop <- read_csv("./data/aspatial/pop.csv")
```

Check the population data per age range.

```{r}
glimpse(pop)
```

## **2 Computing Distance Matrix**

### **2.1 Importing Data**

Use sf package to read master plan subzone data and bus stop location data.

```{r}
mpsz <- st_read(dsn = "./data/geospatial",
                   layer = "MPSZ-2019") %>% st_transform(crs = 3414)
```

### **2.2 Converting from sf data.table to SpatialPolygonsDataFrame**

There are at least two ways to compute the required distance matrix. One is based on sf and the other is based on sp. Past experience shown that computing distance matrix by using sf function took relatively longer time that sp method especially the data set is large. In view of this, sp method is used in the code chunks below.

First [`as.Spatial()`](https://r-spatial.github.io/sf/reference/coerce-methods.html) will be used to convert *mpsz* from sf tibble data frame to SpatialPolygonsDataFrame of sp object as shown in the code chunk below.

```{r}
mpsz_sp <- as(mpsz, "Spatial")
mpsz_sp
```

### 2.3 **Computing the distance matrix**

Next, [`spDists()`](https://www.rdocumentation.org/packages/sp/versions/2.1-1/topics/spDistsN1) of sp package will be used to compute the Euclidean distance between the centroids of the planning subzones.

```{r}
dist <- spDists(mpsz_sp, 
                longlat = FALSE)
head(dist, n=c(10, 10))
```

### **2.4 Labelling column and row heanders of a distance matrix**

First, we will create a list sorted according to the the distance matrix by planning sub-zone code.

```{r}
sz_names <- mpsz$SUBZONE_C
```

Next we will attach `SUBZONE_C` to row and column for distance matrix matching ahead

```{r}
colnames(dist) <- paste0(sz_names)
rownames(dist) <- paste0(sz_names)
```

### 2.5 **Pivoting distance value by SUBZONE_C**

Next, we will pivot the distance matrix into a long table by using the row and column subzone codes as show in the code chunk below.

```{r}
distPair <- melt(dist) %>%
  rename(dist = value)
head(distPair, 10)
```

::: callout-notice
Notice that the within zone distance is 0.
:::

### 2.6 **Updating intra-zonal distances**

In this section, we are going to append a constant value to replace the intra-zonal distance of 0.

First, we will select and find out the minimum value of the distance by using `summary()`.

```{r}
distPair %>%
  filter(dist > 0) %>%
  summary()
```

Next, a constant distance value of 50m is added into intra-zones distance.

```{r}
distPair$dist <- ifelse(distPair$dist == 0,
                        50, distPair$dist)
```

The code chunk below will be used to check the result data.frame.

```{r}
summary(distPair)
```

The code chunk below is used to rename the origin and destination fields.

```{r}
distPair <- distPair %>%
  rename(orig = Var1,
         dest = Var2)
```

The code chunk below is used to rename the origin and destination fields.

```{r}
write_rds(distPair, "./data/rds/distPair.rds") 
```

## **3. Preparing flow data**

Iimport *od_data* save in hands on exercise 3 into R environment.

```{r}
od_data <- read_rds("./data/rds/od_data.rds")
```

Next, we will compute the total passenger trip between and within planning subzones by using the code chunk below. The output is all *flow_data*.

```{r}
flow_data <- od_data %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>% 
  summarize(TRIPS = sum(MORNING_PEAK)) 

head(flow_data, 10)
```

### 3.1 **Separating intra-flow from passenger volume df**

Code chunk below is used to add three new fields in `flow_data` dataframe.

```{r}
flow_data$FlowNoIntra <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0, flow_data$TRIPS)
flow_data$offset <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0.000001, 1)
```

### 3.2 **Combining passenger volume data with distance value**

Before we can join *flow_data* and *distPair*, we need to convert data value type of *ORIGIN_SZ* and *DESTIN_SZ* fields of flow_data dataframe into factor data type.

```{r}
flow_data$ORIGIN_SZ <- as.factor(flow_data$ORIGIN_SZ)
flow_data$DESTIN_SZ <- as.factor(flow_data$DESTIN_SZ)
```

Now, `left_join()` of **dplyr** will be used to *flow_data* dataframe and *distPair* dataframe. The output is called *flow_data1*.

```{r}
flow_data1 <- flow_data %>%
  left_join (distPair,
             by = c("ORIGIN_SZ" = "orig",
                    "DESTIN_SZ" = "dest"))
```

## **4. Preparing Origin and Destination Attributes**

### 4.1 **Geospatial data wrangling**

```{r}
pop <- pop %>%
  left_join(mpsz,
            by = c("PA" = "PLN_AREA_N",
                   "SZ" = "SUBZONE_N")) %>%
  select(1:6) %>%
  rename(SZ_NAME = SZ,
         SZ = SUBZONE_C)
```

### 4.2 **Preparing origin attribute**

```{r}
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(ORIGIN_SZ = "SZ")) %>%
  rename(ORIGIN_AGE7_12 = AGE7_12,
         ORIGIN_AGE13_24 = AGE13_24,
         ORIGIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

### 4.3 **Preparing destination attribute**

```{r}
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(DESTIN_SZ = "SZ")) %>%
  rename(DESTIN_AGE7_12 = AGE7_12,
         DESTIN_AGE13_24 = AGE13_24,
         DESTIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

We will called the output data file *SIM_data*. it is in rds data file format.

```{r}
write_rds(flow_data1, "./data/rds/SIM_data.rds")
```

## 5. **Calibrating Spatial Interaction Models**

In this section, you will learn how to calibrate Spatial Interaction Models by using Poisson Regression method.

### **5.1 Visualising the dependent variable**

```{r}
SIM_data <- read_rds("./data/rds/SIM_data.rds")
```

Firstly, let us plot the distribution of the dependent variable (i.e.Â TRIPS) by using histogram method by using the code chunk below.

```{r}
ggplot(data = SIM_data,
       aes(x = TRIPS)) +
  geom_histogram() +
  theme_light()
```

::: callout-notice
Notice that the distribution is highly skewed and not resemble bell shape or also known as normal distribution.
:::

Next, let us visualise the relation between the dependent variable and one of the key independent variable in Spatial Interaction Model, namely distance.

```{r}
ggplot(data = SIM_data,
       aes(x = dist,
           y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm) +
  theme_light()
```

::: callout-notice
Notice that their relationship hardly resemble linear relationship.
:::

On the other hand, if we plot the scatter plot by using the log transformed version of both variables, we can see that their relationship is more resemble linear relationship.

```{r}
ggplot(data = SIM_data,
       aes(x = log(dist),
           y = log(TRIPS))) +
  geom_point() +
  geom_smooth(method = lm) +
  theme_light()
```
